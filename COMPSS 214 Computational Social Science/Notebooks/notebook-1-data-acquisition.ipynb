{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lgvUMsBY9y__"
   },
   "source": [
    "<div style=\"background-color: #002676; padding: 20px;\">\n",
    "<img src=\"https://macss.berkeley.edu/wp-content/uploads/2023/09/UCBMaCSS_Logo_2Color_Reverse_TaglineB.png\" alt=\"MaCSS\" width=\"300\">\n",
    "</div>\n",
    "\n",
    "# **Notebook 1:** Data Acquisition\n",
    "\n",
    "[wdtmacss@berkeley.edu](mailto:wdtmacss@berkeley.edu)\\\n",
    "**Computational Social Science 1A**\\\n",
    "[Human Psychology and Social Technologies](https://classes.berkeley.edu/content/2024-fall-compss-214a-001-lec-001) \n",
    "Fall 2024\\\n",
    "UC Berkeley [Masters in Computational Social Science](https://macss.berkeley.edu/about/)\n",
    "\n",
    "**Week 2:** An introduction to the [McCabe et al (2024)](https://www.nature.com/articles/s41586-024-07524-8) study and assosciated dataset ([https://github.com/DiogoFerrari/replication-twitter-deplatforming](https://github.com/DiogoFerrari/replication-twitter-deplatforming))\n",
    "\n",
    "📊📉📈📊📉📈📊\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "- [Announcements](#announcments)\n",
    "- [Class Summary](#class-summary)\n",
    "- [Background: Misinformation and Social Media](#background-misinformation-and-social-media)\n",
    "  - [January 6th 2021](#january-6th-2021)\n",
    "  - [Election Misinformation on Twitter](#election-misinformation-on-twitter)\n",
    "  - [What is Misinformation?](#what-is-misinformation)\n",
    "  - [Psychological research on belief formation](#psychological-research-on-belief-formation)\n",
    "- [Class Discussion 1: Does social media change your mind?](#class-discussion-1-does-social-media-change-your-mind)\n",
    "- [Key paper: McCabe et al 2024](#key-paper-mccabe-et-al-2024)\n",
    "  - [Research article](#research-article)\n",
    "  - [Introduction & Summary](#introduction--summary)\n",
    "  - [Class Discussion 2: Key assumptions and study decisions](#class-discussion-2-key-assumptions-and-study-decisions)\n",
    "- [LLM (e.g. ChatGPT) Policy](#chatgpt-policy)\n",
    "- [Class Exercises](#class-exercises)\n",
    "  - [Data Availability](#data-availability)\n",
    "  - [Accessing Data](#accessing-data)\n",
    "  - [Your Challenge Today](#your-challenge-today)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Announcements\n",
    "*   Thank you for Assignment 1 submissions\n",
    "*   Future assignments will be submitted via Gradescope -- if you don't have an account already, I think you will need to sign up for one.\n",
    "*   I have drafted a ChatGPT Policy for the class for future assignments. We will discuss later in the class today.\n",
    "*   There is now a slack channel (`#css1a`) for this class. Feel free to use for discussion.\n",
    "      * I will check sometimes but not routinely -- email remains the mode of contact for official or urgent business\n",
    "*   Grading rubrics and further details for Assignment 2 are forthcoming.\n",
    "*   Questions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Summary\n",
    "Welcome to the first of three lab sessions in part one of the class focusing on misinformation and social media.\n",
    "\n",
    "**Today's Schedule:**\n",
    "*   Announcements\n",
    "*   Mini-lecture and class discussion on misinformation, social media, and belief formation\n",
    "*   Classs discussion of the [McCabe et al (2024)](https://www.nature.com/articles/s41586-024-07524-8) study\n",
    "*   Programming exercise: acquiring and processing the McCabe et al [dataset on Github](https://github.com/DiogoFerrari/replication-twitter-deplatforming)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background: Misinformation and Social Media"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## January 6th 2021\n",
    "\n",
    "A major event in US political life. Here is a brief summary of the sequence of events:\n",
    "* Politicians in the US Capitol on January 6th 2021 were in the process of certifying the November 2020 US Presidential election\n",
    "* **Sitting President Donald Trump claims the outcome of the election (Joe Biden Wins) is illegitemate**\n",
    "* Trump instructs sitting VP Mike Pence to [stop the steal](https://en.wikipedia.org/wiki/Attempts_to_overturn_the_2020_United_States_presidential_election) by not certifying the result\n",
    "* Pence refuses Trump's instruction\n",
    "* Trump gives a long and rousing speech \n",
    "* Trump supporters and others storm the US Capitol building "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Major event in world media \n",
    "\n",
    "<img src=\"https://pbs.twimg.com/media/ErFNB3AVgAEmHGF?format=jpg&name=900x900\" alt=\"Example Image\" width=\"200\" style=\"float:left\"/>\n",
    "<img src=\"https://pbs.twimg.com/media/ErGsWs-XMAM9vWD?format=jpg&name=900x900\" alt=\"Example Image\" width=\"200\" style=\"float:left\"/>\n",
    "<img src=\"https://pbs.twimg.com/media/ErFrWIvWMAcgBH9?format=jpg&name=medium\" alt=\"Example Image\" width=\"200\" style=\"float:left\"/>\n",
    "<img src=\"https://pbs.twimg.com/media/ErGRMPCXYAIhJXY?format=jpg&name=medium\" alt=\"Example Image\" width=\"200\" style=\"float:left\"/>\n",
    "<img src=\"https://pbs.twimg.com/media/ErG_kANVcAEiYE9?format=jpg&name=medium\" alt=\"Example Image\" width=\"200\" style=\"float:left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Election Misinformation on Twitter \n",
    "Twitter has been argued to have played an important role in the events, in large part by facilitating the spread of election misinformation related to the idea that the election outcome was illegitemate.\n",
    "\n",
    "*   Twitter had historically benefitted enourmously from the fact that it was one of President Trump's primary platform for communication with voters, establishing Twitter as a defacto home for political discourse.\n",
    "*   The select committee that later investigated these events focused heavily on a series of Tweets by President Trump and their role in encouraging protestors. Here is a Tweet thread from the select comittee describing their view of the timeline of events: [https://x.com/January6thCmte/status/1479077472356470786](https://x.com/January6thCmte/status/1479077472356470786)\n",
    "\n",
    "<img src=\"https://pbs.twimg.com/media/FIcQm4JXoAAbmY_?format=jpg&name=large\" alt=\"Example Image\" width=\"600\" style=\"float:left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Misinformation?\n",
    "* Misinformation is: information which is fake or misleading and spreads **unintentionally** (emphasis added, definition from: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8853081/)\n",
    "    * Can include rumours, gossip, fake news -- anything which turns out to be false\n",
    "* Not to be confused with *Disinformation*, which is: false information spread deliberately **with the intent to deceive**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Psychological research on belief formation\n",
    "Minsinformation can be dangerous because it can cause or contribute to the formation of **false beliefs**.\n",
    "\n",
    "Here is a **recent review of psychological research** into the role that misnformation can play in the formation of false beliefs, and the factors that make misnformation more or less impactful:\n",
    "\n",
    "Ecker, U. K. et al. (2022). [The psychological drivers of misinformation belief and its resistance to correction](https://www.nature.com/articles/s44159-021-00006-y). *Nature Reviews Psychology*, 1(1), 13-29.\n",
    "\n",
    "## A few highlights from the review paper\n",
    "The psychological literature has studied extensively the factors that lead people to beleive or endorse statements. Here are a few key insights into the psychology of belief formation, taken from the [Ecker, U. K. et al. (2022).](https://www.nature.com/articles/s44159-021-00006-y) review article (see the article for citations and many additional interesting findings).\n",
    "\n",
    "1. When deciding what is true, **people are biased to believe in the validity of information**, and ‘go with their gut’ and intuitions instead of deliberating.\n",
    "    * For example, in March 2020, 31% of Americans agreed that COVID-19 was purposefully created and spread\n",
    "    * Despite the absence of any credible evidence for its intentional development\n",
    "2.  Simply **repeating a claim makes it more believable** than presenting it only once -- a phenomenon known as [the illusory truth effect](https://en.wikipedia.org/wiki/Illusory_truth_effect)\n",
    "    *  **Repetition** increases belief in both misinformation and facts\n",
    "    *  Illusory truth can **persist months** after first exposure\n",
    "    *  Regardless of cognitive ability \n",
    "    *  And **despite contradictory advice** from an accurate source or accurate prior knowledge\n",
    "3. **Information source matters**. Messages are more persuasive and seem more true when:\n",
    "   * they come from **sources perceived to be credible** rather than non-credible\n",
    "   * they come from people who are judged **powerful, attractive, or similar to oneself**\n",
    "   * they come from **experts**\n",
    "   * they come from **in-group members**\n",
    "4. Misinformation can continue to influence people’s thinking **even after they receive a correction and accept it as true!**\n",
    "   * This phenomenon is known as **the continued influence effect**\n",
    "  \n",
    "### However, on the other hand...\n",
    "There is an active debate around whether misinformation of social media actually influences many people at all. We will read a [perspective paper outlining the critical perspective](https://www.nature.com/articles/s41586-024-07417-w) next week, but first -- let's talk through this question by thinking about our own personal experiences. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Discussion 1: Does social media change your mind?\n",
    "1. What social media platforms do people use?\n",
    "2. Has social media played a big role in your political views or activities?\n",
    "3. What about other areas of life? Are there areas where you have learned a lot from social media?\n",
    "4. Does social media change **other people's** minds? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key paper: McCabe et al 2024\n",
    "In 2021, Twitter undertook a highly unusual intervention designed to counteract the spread of misinformation during a critical political event. Under normal circumstances, the effects of social media algorithms on information spread are very difficult to detect. This intervention was unusual because the number of deplatformed users was large, they belonged to a specific group, and the timing was made publicly known.\n",
    "\n",
    "A team of social media researchers examined the effects of this intervention, and published their findings in the world's most prestigous scientific journal.\n",
    "\n",
    "## Research article\n",
    "Here is the research paper\\\n",
    "[Post-January 6th deplatforming reduced the reach of misinformation on Twitter](https://www.nature.com/articles/s41586-024-07524-8)\n",
    "\n",
    "\n",
    "The full reference for the paper is:\n",
    "```\n",
    "@article{mccabe2024post,\n",
    "  title={Post-January 6th deplatforming reduced the reach of misinformation on Twitter},\n",
    "  author={McCabe, Stefan D and Ferrari, Diogo and Green, Jon and Lazer, David MJ and Esterling, Kevin M},\n",
    "  journal={Nature},\n",
    "  volume={630},\n",
    "  number={8015},\n",
    "  pages={132--140},\n",
    "  year={2024},\n",
    "  publisher={Nature Publishing Group UK London}\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "## Introduction & Summary\n",
    "* What does depltforming mean in this context?\n",
    "* Who were the people included in the dataset?\n",
    "* What do we know about the people who were deplatformed?\n",
    "* What is the timeline of relevant events?\n",
    "* What are the main objectives of the research?\n",
    "* What are the key analyses used?\n",
    "* What are the major conclusions?\n",
    "\n",
    "\n",
    "## Class Discussion 2: Key assumptions and study decisions\n",
    "Like all data analysis projects, the study by McCabe et al was made tractable as a result of some key assumptions and design decisions in their analyses. In groups, we are going to discuss some of these assumptions, design decisions, and potential confounds. Each group will be assiged one of the following questions to discuss. Togethor, go through the article to find the parts relevant to your question.\n",
    "\n",
    "1. **Question 1: Classification of Misinformation Tweets** How were Tweets classified as misinformation in this study? Do you think this classification is fair and useful? Can you iagine an alternative, more stringent approach to classification? How might the current classification approach have influenced the results?   \n",
    "2. **Question 2: Classification of Misinformation Sharers** How were users classified as misinformation sharers in this study? Do you think this classification is fair and useful? Can you iagine an alternative, more stringent approach to classification? How might the current classification approach have influenced the results?   \n",
    "3. **Question 3: Classification of Followers** How were users classified as followers of deplatformed users in this study? Do you think this classification is fair and useful? Were multiple alternatives examined? Can you iagine an alternative, more stringent approach to classification? How might the current classification approach have influenced the results?\n",
    "4. **Question 4: Primary Outcome = Daily count of Tweets and Retweets** The primary outcome variable in this study is a daily count of Tweets and Retweets of misinformation. Do you think this outcome variable is natural and useful? Can you iagine an alternative, more informative quantitity to measure and model?\n",
    "5. **Question 5: Synchronous Exit of Right-Wing Users** One potential confound in this study is that it is possible that many users who were not themselves deplatformed, but were behaviorally aligned with deplatformed accounts (e.g. Qanon users), left Twitter voluntarily in favor of emerging right-wing platforms. How do the researchers account for this possibility? How might this parallel exit have influence the findings here? Can you think of alternative ways to account for this confound?\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChatGPT Policy\n",
    "\n",
    "All of us are new to an educational context in which an AI model can take our assignments and exams. So this policy is an initial attempt to integrate these technologies into our learning in a wayt that recognizes their value while also protecting the experiences that helps us learn to write programs and analyze data. Mutual patience and feedback are vital to the process of improving this integration.\n",
    "\n",
    "Here's the basic policy for programming assignments.\n",
    "\n",
    "## An LLM-friendly grading policy for programming assignments\n",
    "* You are **welcome to use Large Language Models such as ChatGPT** to help you write great asssignments. Effective and discerning use of these models is a critical skill that modern data scientists should hone\n",
    "* However, there are two key caveats:\n",
    "   * You must **always first try to solve a problem yourself**. If your solution isn't working, or you can't figure out a good answer, you are welcome to **then give ChatGPT your best attempt** if you wish, and ask it to fix your solution or give you a better one.\n",
    "   * If you choose to use ChatGPT, you must **include in your assignment submission the full transcript of your interaction with the model**. We can use the transcript to check that you have respected the requirement to make an attempt yourself.\n",
    "* We will grade in a way that respects both the final solution, your initial attempts, and your interactions with the model.\n",
    "\n",
    "## Example\n",
    "To give a concrete example: today's class excersise involves writing a series of functions to acquire and process a dataset. For each function, try to write it yourself! If you have difficulty, you are welcome to ask ChatGPT to explain why your function isn't working. The best thing to do would be to use any feedback from the model to make another attempt at writing the function yourself. But you are also allowed to ask the model to provide code directly for the function, and to use the code it provides. \n",
    "\n",
    "The more your transcript evidences meaningful attempts to learn and write code yourself, the better your grade will be. If you simply ask ChatGPT to write code for the whole assignment (all the function and their sequencing) without evidencing attempts to learn and write code yourself, you would get a lower grade. \n",
    "\n",
    "**Trial no-stakes grading on Today's notebook?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IvuKg6rGRBzX"
   },
   "source": [
    "# Class Exercises\n",
    "\n",
    "## Data Availability\n",
    "Here is the Github respository that accompanies the research paper:\\\n",
    "[https://github.com/DiogoFerrari/replication-twitter-deplatforming](https://github.com/DiogoFerrari/replication-twitter-deplatforming)\n",
    "\n",
    "* Only the aggregate data is available publicly.\n",
    "* We cannot access data at the level of individual tweets or individual twitter users' accounts. \n",
    "* Instead, we can accces datasets that include descriptive statistics for tweets and retweets by different *groups* of users at a *daily* time resolution.\n",
    "* For example, we can access datsets that tell us the *average* number of tweets or retweets per user among accounts classified as belonging to the `QAnon` group on a given day, or the equivelant *total* number of tweets and retweets.\n",
    "\n",
    "\n",
    "### Accessing Data\n",
    "This aggregate level data is made available in the Github repository above in the `/data/final/` directory:\\\n",
    "[github.com/DiogoFerrari/replication-twitter-deplatforming/tree/master/data/final/](https://github.com/DiogoFerrari/replication-twitter-deplatforming/tree/master/data/final/)\n",
    "\n",
    "This directory holds data for three different aggregate-level datasets. For example, the dataset `panel-2020-daily-totals.csv` containts aggregate data for the 2020 panel, which is the primary datset for the study.\n",
    "\n",
    "The dataset is actually contained within a subdirectory whose name is `panel-2020-daily-totals.csv`. The [`/data/final/panel-2020-daily-totals.csv/`](https://github.com/DiogoFerrari/replication-twitter-deplatforming/tree/master/data/final/panel-2020-daily-totals.csv) subdirectory containts the full `panel-2020-daily-totals.csv` datset broken down into smaller chunks, with each chunk expressed as a `.part` file.\n",
    "\n",
    "**Note:** This way of structuring data can seem a little confusing at first, but it is not uncommon. In general, Github is not designed to host data -- it is designed to host code. Splitting up big datasets into small `.part` chunks can be a way to bypass filesize limitations that reflect these design priorities.  \n",
    "\n",
    "## Your Challenge Today\n",
    "Your goal in this notebook is to **acquire the datset from Github**. You will compile the many `.part` files into a useable single dataset stored in a Pandas dataframe, and save out the dataframe to your Datahub, so that you can use the data over the next three weeks without needing to acquire it anew each time.\n",
    "\n",
    "\n",
    "You can structure the computation however you wish, but here is one suggestion. Pandas is able to read a Dataframe directly from a URL these days. This means that we can simply acquire the URL for each `.part` file, use the URLs to construct a Pandas `DataFrame` for each file, and then combine the individual dataframes into a single larger dataframe, which you can then write out locally.  \n",
    "\n",
    "1. Use web requests to extract URLs for all `.part` files in the [Github Repository](https://github.com/DiogoFerrari/replication-twitter-deplatforming/tree/master/data/final/), using the Github API.\n",
    "2. Write an iterator to iterate over the URLs and read each into a [Pandas](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) `DataFrame`\n",
    "3. Combine the individuals dataframes into one larger dataframe\n",
    "4. Write out (save) the dataframe locally for future use\n",
    "\n",
    "The code cells below provide two functions for you to complete (`download_part_files` and `combine_dataframes`) and one to debug (`fetch_file_urls_from_github_repo`). Feel free to restructure the code if you wish, but the end result should be a call to the `acquire_dataset` function, which will write out a combined dataset locally as a csv with filename `mccabe-data.csv`.\n",
    "\n",
    "Note that I have written the first function (`fetch_file_urls_from_github_repo`) to illustrate how to interact with the Github API via a web request, since I expect many students will not have experience with web requests. **Try to make sure you understand how this function works and what each line is doing**. To help you get to know this part of the code, **I have deliberately included a simple bug in the function** 🫢. The bug has nothing to do with the API call logic, but hopefully tracking it down will help you understand that logic a little better.  \n",
    "\n",
    "If you find additional bugs or have questions, let me know!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1722373735982,
     "user": {
      "displayName": "William D Thompson",
      "userId": "16532926386286142479"
     },
     "user_tz": 420
    },
    "id": "e2ag_91crf_w"
   },
   "outputs": [],
   "source": [
    "def fetch_file_urls_from_github_repo(github_url):\n",
    "    \"\"\"Returns a list of urls for any .part files within\n",
    "    github_url, which should be a valid Github API url. \n",
    "    \"\"\"\n",
    "\n",
    "    # Get a list of files contained in github_url\n",
    "    web_response = requests.get(github_url)\n",
    "    files = web_response.json()\n",
    "\n",
    "    # create an empty list to hold all the urls\n",
    "    part_file_urls = []\n",
    "\n",
    "    # iterate over the file objects for the files in the repository\n",
    "    for file in files:\n",
    "        if file['name'].endswith('.csv'):\n",
    "            web_response = requests.get(github_url + '/' + file['name'])\n",
    "            subfiles = web_response.json()\n",
    "            for subfile in subfiles:\n",
    "                if subfile['name'].endswith('.part'):\n",
    "                    part_file_urls.append(subfile['download_url'])\n",
    "        if file['name'].endswith('.part'):\n",
    "            part_file_urls.append(file['download_url']) # extract the download urls for each .part file\n",
    "    \n",
    "    return part_file_urls\n",
    "\n",
    "# part_file_urls = fetch_file_urls_from_github_repo('https://github.com/DiogoFerrari/replication-twitter-deplatforming/tree/master/data/final')\n",
    "# print(part_file_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_part_files(part_file_urls):\n",
    "    \"\"\"Returns a list of pandas dataframes.\n",
    "    containing data obtained from a part_file_urls (a list of urls).\n",
    "    \"\"\"\n",
    "    individual_dataframes = []\n",
    "\n",
    "    for url in part_file_urls:\n",
    "        df = pd.read_csv(url, sep=';')\n",
    "        individual_dataframes.append(df)\n",
    "\n",
    "    return individual_dataframes\n",
    "\n",
    "# individual_dataframes = download_part_files(part_file_urls)\n",
    "# print(individual_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_dataframes(individual_dataframes):\n",
    "    \"\"\"Takes a list of dataframes\n",
    "    returns a single Pandas dataframe combining them.\n",
    "    \"\"\"\n",
    "\n",
    "    combined_dataframe = pd.concat(individual_dataframes, axis=0)\n",
    "\n",
    "    return combined_dataframe\n",
    "\n",
    "# combine_dataframes = combine_dataframes(individual_dataframes)\n",
    "# print(combine_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 453,
     "status": "ok",
     "timestamp": 1722373736433,
     "user": {
      "displayName": "William D Thompson",
      "userId": "16532926386286142479"
     },
     "user_tz": 420
    },
    "id": "v9Icl-IDlxqk"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cf/1wy60mt16_d0n286_h30f6nh0000gn/T/ipykernel_83368/1348117847.py:6: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_dataframe = pd.concat(individual_dataframes, axis=0)\n"
     ]
    }
   ],
   "source": [
    "def acquire_dataset(repository_url):\n",
    "    \"\"\"\n",
    "    Top-level function that coordinates the individual computations\n",
    "    and writes out the resulting dataframe as a csv to mccabe-data.csv.\n",
    "    \"\"\"\n",
    "    # notice that we are using api.github.com.... to query the Github REST API\n",
    "    api_url = repository_url.replace(\"github.com\", \"api.github.com/repos\").replace(\"tree/master\", \"contents\")\n",
    "\n",
    "    # Fetch urls for part files\n",
    "    part_file_urls = fetch_file_urls_from_github_repo(api_url)\n",
    "    \n",
    "    # Download part files\n",
    "    part_file_dataframes = download_part_files(part_file_urls)\n",
    "\n",
    "    # Combine part files\n",
    "    data = combine_dataframes(part_file_dataframes)\n",
    "\n",
    "    # save the data\n",
    "    data.to_csv('mccabe-2020-data.csv', index=False)\n",
    "\n",
    "acquire_dataset('https://github.com/DiogoFerrari/replication-twitter-deplatforming/tree/master/data/final/panel-2020-daily-totals.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             date  fake_merged  fake_merged_initiation  fake_merged_rt  \\\n",
      "0      2020-07-01   377.000000              121.000000      256.000000   \n",
      "1      2020-07-02   343.000000              116.000000      227.000000   \n",
      "2      2020-07-03   351.000000              110.000000      241.000000   \n",
      "3      2020-07-04   264.000000               64.000000      200.000000   \n",
      "4      2020-07-05   208.000000               49.000000      159.000000   \n",
      "...           ...          ...                     ...             ...   \n",
      "65929  2021-05-28     0.135198                0.013986        0.121212   \n",
      "65930  2021-05-29     0.090186                0.013263        0.076923   \n",
      "65931  2021-05-30     0.100295                0.011799        0.088496   \n",
      "65932  2021-05-31     0.092025                0.012270        0.079755   \n",
      "65933  2020-07-07     0.125604                0.038647        0.086957   \n",
      "\n",
      "       fake_grinberg_initiation  fake_grinberg_rt  \\\n",
      "0                     33.000000         85.000000   \n",
      "1                     33.000000         76.000000   \n",
      "2                     27.000000         58.000000   \n",
      "3                     19.000000         51.000000   \n",
      "4                     17.000000         48.000000   \n",
      "...                         ...               ...   \n",
      "65929                  0.002331          0.023310   \n",
      "65930                  0.002653          0.015915   \n",
      "65931                  0.005900          0.011799   \n",
      "65932                  0.009202          0.015337   \n",
      "65933                  0.004831          0.024155   \n",
      "\n",
      "       fake_grinberg_rb_initiation  fake_grinberg_rb_rt  \\\n",
      "0                        14.000000            26.000000   \n",
      "1                        15.000000            26.000000   \n",
      "2                        13.000000            16.000000   \n",
      "3                         9.000000            11.000000   \n",
      "4                         5.000000            16.000000   \n",
      "...                            ...                  ...   \n",
      "65929                     0.000000             0.002331   \n",
      "65930                     0.000000             0.007958   \n",
      "65931                     0.002950             0.005900   \n",
      "65932                     0.006135             0.006135   \n",
      "65933                     0.000000             0.000000   \n",
      "\n",
      "       fake_newsguard_initiation  fake_newsguard_rt  ...  not_fake_shopping  \\\n",
      "0                     112.000000         238.000000  ...          71.000000   \n",
      "1                     111.000000         202.000000  ...          73.000000   \n",
      "2                     107.000000         222.000000  ...          63.000000   \n",
      "3                      61.000000         185.000000  ...          61.000000   \n",
      "4                      46.000000         144.000000  ...          71.000000   \n",
      "...                          ...                ...  ...                ...   \n",
      "65929                   0.011655           0.114219  ...           0.011655   \n",
      "65930                   0.013263           0.076923  ...           0.010610   \n",
      "65931                   0.011799           0.088496  ...           0.041298   \n",
      "65932                   0.012270           0.076687  ...           0.049080   \n",
      "65933                   0.038647           0.067633  ...           0.000000   \n",
      "\n",
      "       not_fake_shopping_initiation  not_fake_shopping_rt  not_fake_sports  \\\n",
      "0                         21.000000             50.000000         4.000000   \n",
      "1                         21.000000             52.000000        11.000000   \n",
      "2                         16.000000             47.000000         9.000000   \n",
      "3                         27.000000             34.000000         6.000000   \n",
      "4                         20.000000             51.000000         5.000000   \n",
      "...                             ...                   ...              ...   \n",
      "65929                      0.004662              0.006993         0.002331   \n",
      "65930                      0.000000              0.010610         0.000000   \n",
      "65931                      0.035398              0.005900         0.002950   \n",
      "65932                      0.039877              0.009202         0.003067   \n",
      "65933                      0.000000              0.000000         0.004831   \n",
      "\n",
      "       not_fake_sports_initiation  not_fake_sports_rt            n   stat  \\\n",
      "0                             2.0            2.000000  4954.000000  total   \n",
      "1                             7.0            4.000000  5027.000000  total   \n",
      "2                             3.0            6.000000  4640.000000  total   \n",
      "3                             4.0            2.000000  4110.000000  total   \n",
      "4                             2.0            3.000000  3563.000000  total   \n",
      "...                           ...                 ...          ...    ...   \n",
      "65929                         0.0            0.002331     3.764569    avg   \n",
      "65930                         0.0            0.000000     3.456233    avg   \n",
      "65931                         0.0            0.002950     3.303835    avg   \n",
      "65932                         0.0            0.003067     3.226994    avg   \n",
      "65933                         0.0            0.004831     3.125604    avg   \n",
      "\n",
      "       nusers  group  \n",
      "0        3021    fns  \n",
      "1        3045    fns  \n",
      "2        2836    fns  \n",
      "3        2582    fns  \n",
      "4        2206    fns  \n",
      "...       ...    ...  \n",
      "65929     429   F_la  \n",
      "65930     377   F_la  \n",
      "65931     339   F_la  \n",
      "65932     326   F_la  \n",
      "65933     207   F_la  \n",
      "\n",
      "[65934 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "print(pd.read_csv('mccabe-data.csv', sep=','))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Thank you** and I hope you found these discussions and exersises useful 🙏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOBSO3b67kul+Q8WC2Ok7AY",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
